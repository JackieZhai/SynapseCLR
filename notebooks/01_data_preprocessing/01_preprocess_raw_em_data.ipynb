{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "horizontal-front",
   "metadata": {},
   "source": [
    "## Preprocess raw 3D EM image chunks\n",
    "\n",
    "- Convert 256 x 256 x 256 EM and segmentation masks at ~ 8 nm x 8 nm x 40 nm resolution to 2 x 256 x 256 x 52 uint8 tensors. We only keep the central z-sections and remove the unwanted extra context. The two channels corresponds to EM intensity and integer-encoded segmentation masks.\n",
    "- Generate a .csv table of all image chunks and associated metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from typing import Tuple\n",
    "import bisect\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "from synapse_augmenter import consts\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "log_info = print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-fireplace",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_em_data_path = 'path/to/raw/em/data'\n",
    "raw_mask_data_path = 'path/to/raw/mask/data'\n",
    "proc_data_path = 'path/to/processed/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "# promote sections with at least this much fraction of cutout pixels to fully masked\n",
    "cutout_threshold = 0.01\n",
    "\n",
    "# z spacing vs. xy spacing\n",
    "axial_to_sagittal_spacing = 5\n",
    "\n",
    "seg_mask_map = {\n",
    "    'MASK_PRE_SYNAPTIC_NEURON': consts.MASK_PRE_SYNAPTIC_NEURON,\n",
    "    'MASK_SYNAPTIC_CLEFT': consts.MASK_SYNAPTIC_CLEFT,\n",
    "    'MASK_POST_SYNAPTIC_NEURON': consts.MASK_POST_SYNAPTIC_NEURON\n",
    "}\n",
    "\n",
    "# which segmentation region(s) to cut the EM data with?\n",
    "cut_intensity_with_seg_masks = False\n",
    "output_channel_desc = [\n",
    "    (consts.MASK_PRE_SYNAPTIC_NEURON,),\n",
    "    (consts.MASK_SYNAPTIC_CLEFT,),\n",
    "    (consts.MASK_POST_SYNAPTIC_NEURON,)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-jackson",
   "metadata": {},
   "source": [
    "## List of all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_em_data_file_path_list = []\n",
    "for dirpath, _, filenames in os.walk(raw_em_data_path):\n",
    "    for filename in filenames:\n",
    "        if filename.find('.npy') != '-1':\n",
    "            raw_em_data_file_path_list.append(os.path.join(dirpath, filename))\n",
    "            \n",
    "raw_mask_data_file_path_list = []\n",
    "for dirpath, _, filenames in os.walk(raw_mask_data_path):\n",
    "    for filename in filenames:\n",
    "        if filename.find('.npy') != '-1':\n",
    "            raw_mask_data_file_path_list.append(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe\n",
    "\n",
    "def get_id_from_em_data_path(em_data_path: str) -> str:\n",
    "    return em_data_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "def get_id_from_mask_data_path(mask_data_path: str) -> str:\n",
    "    return mask_data_path.split('/')[-1].split('.')[0].split('_')[0]\n",
    "\n",
    "synapse_id_to_em_data_path_map = {\n",
    "    get_id_from_em_data_path(em_data_path): em_data_path\n",
    "    for em_data_path in raw_em_data_file_path_list\n",
    "}\n",
    "\n",
    "synapse_id_to_mask_data_path_map = {\n",
    "    get_id_from_mask_data_path(mask_data_path): mask_data_path\n",
    "    for mask_data_path in raw_mask_data_file_path_list\n",
    "}\n",
    "\n",
    "# synapose IDs with both EM data and mask data\n",
    "complete_synapse_id_set = set(synapse_id_to_em_data_path_map.keys()).intersection(set(synapse_id_to_mask_data_path_map.keys()))\n",
    "complete_synapse_id_list = sorted(list(complete_synapse_id_set))\n",
    "complete_em_data_path_list = list(map(synapse_id_to_em_data_path_map.get, complete_synapse_id_list))\n",
    "complete_mask_data_path_list = list(map(synapse_id_to_mask_data_path_map.get, complete_synapse_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_em_data_and_mask(synapse_id: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    assert synapse_id in complete_synapse_id_set\n",
    "    em_data_xyz = np.load(synapse_id_to_em_data_path_map[synapse_id])\n",
    "    mask_data_xyz = np.load(synapse_id_to_mask_data_path_map[synapse_id])\n",
    "    return em_data_xyz, mask_data_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-fight",
   "metadata": {},
   "source": [
    "## Estimate cutout pixel fraction across the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutout_fraction_z(img_xyz: np.ndarray, cutout_pixel_value: int = 0) -> float:\n",
    "    section_area = img_xyz.shape[0] * img_xyz.shape[1]\n",
    "    cutout_fraction_z = np.sum(img_xyz == cutout_pixel_value, axis=(0, 1)) / section_area\n",
    "    return cutout_fraction_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rand_samples = 1000\n",
    "log_freq = 100\n",
    "n_bins = 100\n",
    "\n",
    "hist = np.zeros((n_bins,))\n",
    "\n",
    "for i_img in range(n_rand_samples):\n",
    "    \n",
    "    if i_img % log_freq == 0:\n",
    "        log_info(f\"Processing {i_img + 1} / {n_rand_samples} ...\")\n",
    "    \n",
    "    # load a random image\n",
    "    synapse_index = np.random.randint(0, len(complete_synapse_id_list))\n",
    "    img_xyz, _ = load_em_data_and_mask(complete_synapse_id_list[synapse_index])\n",
    "    \n",
    "    # estimate cutout fraction and histogram\n",
    "    cutout_fraction_z = get_cutout_fraction_z(img_xyz)\n",
    "    c_hist, values = np.histogram(cutout_fraction_z, bins=n_bins)\n",
    "    \n",
    "    # accumulate histogram\n",
    "    hist += c_hist\n",
    "    \n",
    "hist = hist / (n_rand_samples * img_xyz.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_points = 0.5 * (values[1:] + values[:-1])\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.scatter(mid_points, hist, s=1)\n",
    "ax.set_xlabel('Cutout pixel fraction')\n",
    "ax.set_ylabel('Fraction of sections')\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cutout_threshold >= values[1] - values[0]\n",
    "lo_idx = bisect.bisect_left(values, cutout_threshold)\n",
    "total_weight_lo_cutout = np.sum(hist[:lo_idx])\n",
    "total_weight_hi_cutout = np.sum(hist[lo_idx:])\n",
    "\n",
    "log_info(f'Fraction of sections with less than {cutout_threshold} fraction masking: {total_weight_lo_cutout}')\n",
    "log_info(f'Fraction of sections with more than {cutout_threshold} fraction masking: {total_weight_hi_cutout}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-advisory",
   "metadata": {},
   "source": [
    "## Intensity histogram of non-masked sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rand_samples = 10\n",
    "log_freq = 100\n",
    "\n",
    "intensity_counter = Counter()\n",
    "\n",
    "for i_img in range(n_rand_samples):\n",
    "    \n",
    "    if i_img % log_freq == 0:\n",
    "        log_info(f\"Processing {i_img + 1} / {n_rand_samples} ...\")\n",
    "    \n",
    "    # load a random image\n",
    "    synapse_index = np.random.randint(0, len(complete_synapse_id_list))\n",
    "    img_xyz, _ = load_em_data_and_mask(complete_synapse_id_list[synapse_index])\n",
    "    \n",
    "    # calcualte cutout fraction for each section\n",
    "    cutout_fraction_z = get_cutout_fraction_z(img_xyz)\n",
    "    sub_threshold_cutout_sections_z = cutout_fraction_z <= cutout_threshold\n",
    "    img_xyz = img_xyz[:, :, sub_threshold_cutout_sections_z]\n",
    "    \n",
    "    # update indensity counter\n",
    "    intensity_counter.update(img_xyz.flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_hist = list(map(itemgetter(1), sorted(list(dict(intensity_counter).items()), key=itemgetter(0))))[1:]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(intensity_hist)\n",
    "ax.set_xlabel('Intensity')\n",
    "ax.set_ylabel('Pixel count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-murray",
   "metadata": {},
   "source": [
    "## Section-to-section intensity variation estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rand_samples = 10\n",
    "log_freq = 100\n",
    "\n",
    "section_to_section_relative_intensity_list = []\n",
    "\n",
    "for i_img in range(n_rand_samples):\n",
    "    \n",
    "    if i_img % log_freq == 0:\n",
    "        log_info(f\"Processing {i_img + 1} / {n_rand_samples} ...\")\n",
    "    \n",
    "    # load a random image\n",
    "    synapse_index = np.random.randint(0, len(complete_synapse_id_list))\n",
    "    img_xyz, _ = load_em_data_and_mask(complete_synapse_id_list[synapse_index])\n",
    "    \n",
    "    # calcualte cutout fraction for each section\n",
    "    cutout_fraction_z = get_cutout_fraction_z(img_xyz)\n",
    "    sub_threshold_cutout_sections_z = cutout_fraction_z <= cutout_threshold\n",
    "    img_xyz = img_xyz[:, :, sub_threshold_cutout_sections_z]\n",
    "    \n",
    "    section_mean_z = np.mean(img_xyz, axis=(0, 1))\n",
    "    relative_section_mean_z = section_mean_z[:-1] / (1e-8 + section_mean_z[1:])\n",
    "    \n",
    "    section_to_section_relative_intensity_list += relative_section_mean_z.tolist()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img_xyz[:, :, 13].flatten(), bins=255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.01\n",
    "b = 0\n",
    "intensity_tansform = lambda x: np.clip(a * x + b, a_min=0., a_max=255.)\n",
    "\n",
    "plt.hist(intensity_tansform(img_xyz[:, :, 14].astype(np.float).flatten()), bins=255);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-probability",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "For each image:\n",
    "\n",
    "- Keep track of the number sections with supra-threshold cutout pixels\n",
    "- Mask the entire section with supra-threshold cutout pixels\n",
    "- Center crop to (256, 256, 256 // axial_to_sagittal_spacing + 1)\n",
    "- Generate output channels by applying segmentation mask to EM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_3d_np(layer: np.ndarray, target_shape: Tuple[int]) -> np.ndarray:\n",
    "    layer_depth, layer_height, layer_width = layer.shape\n",
    "    target_depth, target_height, target_width = target_shape\n",
    "    assert layer_depth >= target_depth\n",
    "    assert layer_height >= target_height\n",
    "    assert layer_width >= target_width\n",
    "    diff_x = (layer_width - target_width) // 2\n",
    "    diff_y = (layer_height - target_height) // 2\n",
    "    diff_z = (layer_depth - target_depth) // 2\n",
    "    return layer[\n",
    "        diff_z:(diff_z + target_depth),\n",
    "        diff_y:(diff_y + target_height),\n",
    "        diff_x:(diff_x + target_width)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(proc_data_path, exist_ok=True)\n",
    "\n",
    "log_frequency = 500\n",
    "\n",
    "out_filename_list = []\n",
    "n_cutout_sections_list = []\n",
    "pre_synaptic_neuron_volume_list = []\n",
    "post_synaptic_neuron_volume_list = []\n",
    "synaptic_cleft_volume_list = []\n",
    "\n",
    "for i_synapse, synapse_id in enumerate(complete_synapse_id_list):\n",
    "\n",
    "    # load raw data\n",
    "    em_xyz, mask_xyz = load_em_data_and_mask(synapse_id)\n",
    "\n",
    "    # match axial and sagittal resolutions and re-crop (for EM data)\n",
    "    orig_shape = em_xyz.shape\n",
    "    final_shape = orig_shape[0], orig_shape[1], (orig_shape[2] // axial_to_sagittal_spacing + 1)\n",
    "    em_xyz = center_crop_3d_np(em_xyz, final_shape)\n",
    "\n",
    "    # match axial and sagittal resolutions and re-crop (for mask data)\n",
    "    orig_shape = mask_xyz.shape\n",
    "    final_shape = orig_shape[0], orig_shape[1], (orig_shape[2] // axial_to_sagittal_spacing + 1)\n",
    "    mask_xyz = center_crop_3d_np(mask_xyz, final_shape)\n",
    "\n",
    "    # calcualte masked fraction for each section\n",
    "    cutout_fraction_z = get_cutout_fraction_z(em_xyz)\n",
    "    supra_threshold_cutout_sections_z = cutout_fraction_z > cutout_threshold\n",
    "    n_cutout_sections = np.sum(supra_threshold_cutout_sections_z)\n",
    "\n",
    "    # promote partially masked to fully masked\n",
    "    em_xyz[:, :, supra_threshold_cutout_sections_z] = 0\n",
    "\n",
    "    if cut_intensity_with_seg_masks:\n",
    "\n",
    "        # generate output channels\n",
    "        n_output_channels = len(output_channel_desc) + 1\n",
    "        out_cxyz = np.zeros((n_output_channels,) + em_xyz.shape, dtype=em_xyz.dtype)\n",
    "\n",
    "        # cut the EM data with mask combinations\n",
    "        for i_output_channel, seg_mask_tuple in enumerate(output_channel_desc):\n",
    "            combined_mask_xyz = np.zeros_like(mask_xyz)\n",
    "            for seg_mask_value in seg_mask_tuple:\n",
    "                combined_mask_xyz = combined_mask_xyz | (mask_xyz == seg_mask_value)\n",
    "            out_cxyz[i_output_channel, ...] = combined_mask_xyz * em_xyz\n",
    "\n",
    "        # include the integer segmentation mask as the last channel\n",
    "        out_cxyz[-1, ...] = mask_xyz\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # intensity and integer seg mask\n",
    "        n_output_channels = 2\n",
    "        out_cxyz = np.zeros((n_output_channels,) + em_xyz.shape, dtype=em_xyz.dtype)\n",
    "        out_cxyz[0, ...] = em_xyz\n",
    "        out_cxyz[1, ...] = mask_xyz\n",
    "    \n",
    "    # statistics\n",
    "    pre_synaptic_neuron_volume = axial_to_sagittal_spacing * np.sum(mask_xyz == consts.MASK_PRE_SYNAPTIC_NEURON)\n",
    "    post_synaptic_neuron_volume = axial_to_sagittal_spacing * np.sum(mask_xyz == consts.MASK_POST_SYNAPTIC_NEURON)\n",
    "    synaptic_cleft_volume = axial_to_sagittal_spacing * np.sum(mask_xyz == consts.MASK_SYNAPTIC_CLEFT)\n",
    "    \n",
    "    # save\n",
    "    out_filename = f\"{synapse_id}__{'_'.join([str(x) for x in out_cxyz.shape])}.npy\"\n",
    "    np.save(os.path.join(proc_data_path, out_filename), out_cxyz)\n",
    "\n",
    "    # bookkeeping\n",
    "    out_filename_list.append(out_filename)\n",
    "    n_cutout_sections_list.append(n_cutout_sections)\n",
    "    pre_synaptic_neuron_volume_list.append(pre_synaptic_neuron_volume)\n",
    "    post_synaptic_neuron_volume_list.append(post_synaptic_neuron_volume)\n",
    "    synaptic_cleft_volume_list.append(synaptic_cleft_volume)\n",
    "    \n",
    "    if i_synapse % log_frequency == 0:\n",
    "        log_info(f'Processing {i_synapse + 1} / {len(complete_synapse_id_list)} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-beads",
   "metadata": {},
   "source": [
    "## Save the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_df = pd.DataFrame(\n",
    "    {\n",
    "        'synapse_id': pd.Series(complete_synapse_id_list, dtype='str'),\n",
    "        'filename': pd.Series(out_filename_list, dtype='str'),\n",
    "        'pre_synaptic_volume': pd.Series(pre_synaptic_neuron_volume_list, dtype='float'),\n",
    "        'post_synaptic_volume': pd.Series(post_synaptic_neuron_volume_list, dtype='float'),\n",
    "        'synaptic_cleft_volume': pd.Series(synaptic_cleft_volume_list, dtype='float'),\n",
    "        'n_cutout_sections': pd.Series(n_cutout_sections_list, dtype='int')\n",
    "    }\n",
    ")\n",
    "\n",
    "# save\n",
    "proc_data_df.to_csv(os.path.join(proc_data_path, 'meta.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-suspect",
   "metadata": {},
   "source": [
    "## Merge datasets\n",
    "\n",
    "If multiple downloaded datasets are processed, we need to merge the metdata to make a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_list = [\n",
    "    'path/to/processed/dataset_1/meta.csv',\n",
    "    'path/to/processed/dataset_2/meta.csv',\n",
    "    'path/to/processed/dataset_3/meta.csv',\n",
    "]\n",
    "\n",
    "merged_meta_path = 'path/to/processed/dataset_merged/meta.csv'\n",
    "\n",
    "meta_df_list = [pd.read_csv(meta_path, index_col='synapse_id') for meta_path in meta_list]\n",
    "merged_meta_df = pd.concat(meta_df_list, sort=True)\n",
    "\n",
    "merged_meta_df = merged_meta_df.drop_duplicates().reset_index(drop=False)\n",
    "\n",
    "# save\n",
    "merged_meta_df.to_csv(merged_meta_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
